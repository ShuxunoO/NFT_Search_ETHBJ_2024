{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_dir(dir_path):\n",
    "    \"\"\"\n",
    "    检查文件夹路径是否存在，不存在则创建\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): 待检查的文件夹路径\n",
    "    \"\"\"\n",
    "    if not dir_path.exists():\n",
    "        try:\n",
    "            dir_path.mkdir(parents=True)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "def load_json(json_path):\n",
    "    \"\"\"\n",
    "    以只读的方式打开json文件\n",
    "\n",
    "    Args:\n",
    "        config_path: json文件路径\n",
    "\n",
    "    Returns:\n",
    "        A dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r', encoding='UTF-8') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def save_json(save_path, data):\n",
    "    \"\"\"\n",
    "    Saves the data to a file with the given filename in the given path\n",
    "\n",
    "    Args:\n",
    "        :param save_path: The path to the folder where you want to save the file\n",
    "        :param filename: The name of the file to save\n",
    "        :param data: The data to be saved\n",
    "\n",
    "    \"\"\"\n",
    "    with open(save_path, 'w', encoding='UTF-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "class Make_Extraction_CSV_Index():\n",
    "    def __init__(self, len_per_project, project_name_list, base_path, out_path) -> None:\n",
    "        self.len_per_project = len_per_project\n",
    "        self.project_name_list = project_name_list\n",
    "        self.base_path = base_path\n",
    "        self.out_path = out_path\n",
    "\n",
    "    def make_dataset_index(self):\n",
    "        self.make_img_caption_dict()\n",
    "    \n",
    "    def make_img_caption_dict(self):\n",
    "        dict_template = {\n",
    "            \"length\" : {},\n",
    "            \"project_name_list\": self.project_name_list,\n",
    "            \"extraction_dict\": {}\n",
    "            }\n",
    "        # 制作NFT1000的索引文件\n",
    "\n",
    "        for project_name in tqdm(self.project_name_list):\n",
    "            # 拼凑字典路径\n",
    "            project_path = self.base_path.joinpath(project_name, \"caption\",  \"_caption_dict.json\")\n",
    "            # 读取字典\n",
    "            caption_dict = load_json(project_path).get(\"caption_dict\")\n",
    "            img_path_list = [self.base_path.joinpath(project_name,\"img\",img_name).as_posix() for img_name in list(caption_dict.keys())]\n",
    "            target_caption_dict = {k: v for k, v in zip(img_path_list, caption_dict.values())}\n",
    "            dict_template[\"extraction_dict\"].update(target_caption_dict)\n",
    "\n",
    "        dict_template[\"length\"][\"extraction_dict\"] = len(dict_template[\"extraction_dict\"])\n",
    "        # 保存到json文件\n",
    "\n",
    "        print(\"\\n##########  saving……  ##########\\n\")\n",
    "        self.save_json(self.out_path.joinpath(\"ETHBJ_top100_extraction_projects.json\"), dict_template)\n",
    "        print(\"\\n##########  img_caption_dict is saved successfully!  ##########\\n\")\n",
    "\n",
    "    def save_json(self, save_path, data):\n",
    "        \"\"\"\n",
    "        Saves the data to a file with the given filename in the given path\n",
    "\n",
    "        Args:\n",
    "            :param save_path: The path to the folder where you want to save the file\n",
    "            :param data: The data to be saved\n",
    "\n",
    "        \"\"\"\n",
    "        with open(save_path, 'w', encoding='UTF-8') as file:\n",
    "            json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    def load_json(self, json_path):\n",
    "        \"\"\"\n",
    "        以只读的方式打开json文件\n",
    "\n",
    "        Args:\n",
    "            config_path: json文件路径\n",
    "\n",
    "        Returns:\n",
    "            A dictionary\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "\n",
    "            with open(json_path, 'r', encoding='UTF-8') as f:\n",
    "                return json.load(f)\n",
    "        except Exception as e:\n",
    "            print(\"Error loading json file: {}\".format(json_path))\n",
    "            print(e)\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    #################################################################################\n",
    "    ############################# 不同终端的替换范围 开始 #############################\n",
    "\n",
    "    source_path = Path(\"/data/sswang/data/NFT1000/\")\n",
    "    target_path = Path(\"/data/sswang/NFT_search/NFT_Search_ETHBJ_2024/data/\")\n",
    "\n",
    "    ############################# 不同终端的替换范围 结束 #############################\n",
    "    #################################################################################\n",
    "\n",
    "\n",
    "    # dataset_dict = load_json(source_path.joinpath(\"_index\", \"dataset_index.json\"))\n",
    "\n",
    "    project_name_list = [\n",
    "        \"BoredApeYachtClub\",\n",
    "        \"CRYPTOPUNKS\",\n",
    "        \"MutantApeYachtClub\",\n",
    "        \"Azuki\",\n",
    "        \"CloneX\",\n",
    "        \"Moonbirds\",\n",
    "        \"Doodles\",\n",
    "        \"BoredApeKennelClub\",\n",
    "        \"Cool Cats\",\n",
    "        \"Beanz\",\n",
    "        \"PudgyPenguins\",\n",
    "        \"Cryptoadz\",\n",
    "        \"World Of Women\",\n",
    "        \"CyberKongz\",\n",
    "        \"0N1 Force\",\n",
    "        \"MekaVerse\",\n",
    "        \"HAPE PRIME\",\n",
    "        \"mfers\",\n",
    "        \"projectPXN\",\n",
    "        \"Karafuru\",\n",
    "        \"Invisible Friends\",\n",
    "        \"FLUF\",\n",
    "        \"Milady\",\n",
    "        \"goblintown\",\n",
    "        \"Phanta Bear\",\n",
    "        \"CyberKongz VX\",\n",
    "        \"KaijuKingz\",\n",
    "        \"Prime Ape Planet\",\n",
    "        \"Lazy Lions\",\n",
    "        \"3Landers\",\n",
    "        \"The Doge Pound\",\n",
    "        \"DeadFellaz\",\n",
    "        \"World Of Women Galaxy\",\n",
    "        \"ALIENFRENS\",\n",
    "        \"VOX Series 1\",\n",
    "        \"Hashmasks\",\n",
    "        \"Psychedelics Anonymous Genesis\",\n",
    "        \"RENGA\",\n",
    "        \"CoolmansUniverse\",\n",
    "        \"Art Gobblers\",\n",
    "        \"SupDucks\",\n",
    "        \"Jungle Freaks\",\n",
    "        \"Sneaky Vampire Syndicate\",\n",
    "        \"SuperNormalbyZipcy\",\n",
    "        \"Nakamigos\",\n",
    "        \"Impostors Genesis\",\n",
    "        \"Potatoz\",\n",
    "        \"CryptoSkulls\",\n",
    "        \"Moonbirds Oddities\",\n",
    "        \"RumbleKongLeague\",\n",
    "        \"MURI\",\n",
    "        \"Galactic Apes\",\n",
    "        \"Lives of Asuna\",\n",
    "        \"My Pet Hooligan\",\n",
    "        \"Murakami.Flowers\",\n",
    "        \"Kiwami\",\n",
    "        \"SHIBOSHIS\",\n",
    "        \"Sappy Seals\",\n",
    "        \"DEGEN TOONZ\",\n",
    "        \"Killer GF\",\n",
    "        \"CryptoMories\",\n",
    "        \"Crypto Bull Society\",\n",
    "        \"CryptoBatz by Ozzy Osbourne\",\n",
    "        \"Quirkies\",\n",
    "        \"Robotos\",\n",
    "        \"Tubby Cats\",\n",
    "        \"Chain Runners\",\n",
    "        \"MutantCats\",\n",
    "        \"Boss Beauties\",\n",
    "        \"OnChainMonkey\",\n",
    "        \"Rektguy\",\n",
    "        \"Desperate ApeWives\",\n",
    "        \"DigiDaigaku\",\n",
    "        \"DeGods\",\n",
    "        \"apekidsclub\",\n",
    "        \"The Humanoids\",\n",
    "        \"Sevens Token\",\n",
    "        \"Akutars\",\n",
    "        \"HypeBears\",\n",
    "        \"KIA\",\n",
    "        \"inbetweeners\",\n",
    "        \"C-01 Official Collection\",\n",
    "        \"Imaginary Ones\",\n",
    "        \"ZombieClub Token\",\n",
    "        \"Groupies\",\n",
    "        \"Valhalla\",\n",
    "        \"MOAR by Joan Cornella\",\n",
    "        \"the littles NFT\",\n",
    "        \"The Heart Project\",\n",
    "        \"CryptoDads\",\n",
    "        \"Chimpers\",\n",
    "        \"Crypto Chicks\",\n",
    "        \"WonderPals\",\n",
    "        \"LilPudgys\",\n",
    "        \"a KID called BEAST\",\n",
    "        \"Akuma\",\n",
    "        \"Cyber Snails\",\n",
    "        \"Variant\",\n",
    "        \"OKOKU\",\n",
    "        \"Dodoor NFT\",\n",
    "        \"Weirdo Ghost Gang\"\n",
    "    ]\n",
    "    NFT1000_maker = Make_Extraction_CSV_Index(21, project_name_list, source_path, target_path)\n",
    "    NFT1000_maker.make_dataset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extraction_img_caption_dict_path = \"/data/sswang/NFT_search/NFT_Search_ETHBJ_2024/data/ETHBJ_top100_extraction_projects.json\"\n",
    "nft_name_address_dict_path = \"/data/sswang/NFT_search/NFT_Search_ETHBJ_2024/data/ETHBJ_top100_name_address.json\"\n",
    "nft_name_address_dict = load_json(nft_name_address_dict_path)\n",
    "base_path = \"/data/sswang/NFT_search/NFT_Search_ETHBJ_2024/data\"\n",
    "dict_info = load_json(extraction_img_caption_dict_path).get(\"extraction_dict\")\n",
    "img_path_list = [img_path for img_path in dict_info.keys()]\n",
    "img_path_obj_list = [Path(img_path) for img_path in img_path_list]\n",
    "NFT_name_list = [path_obj_item.parts[-3] for path_obj_item in img_path_obj_list]\n",
    "token_ID_list = [int(path_obj_item.stem.split(\"_\")[-1]) for path_obj_item in img_path_obj_list]\n",
    "chain_ID_list = [1] * len(img_path_list)\n",
    "\n",
    "contract_address = []\n",
    "for nft_name in NFT_name_list:\n",
    "    contract_address.append(nft_name_address_dict.get(nft_name)[0])\n",
    "data_frame = zip(img_path_list, dict_info.values(), NFT_name_list,  token_ID_list, chain_ID_list, contract_address)\n",
    "csv_path = Path(base_path).joinpath(\"ETHBJ_top100_extraction_projects_index.csv\")\n",
    "with open(csv_path, \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow([\"filepath\", \"caption\", \"NFT_name\", \"token_ID\", \"chain_ID\", \"contract_address\"])\n",
    "    csv_writer.writerows(data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 依照不同的项目对数据总索引表拆分成不同的子表\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100_extraction_projects_index_path = Path(\"/data/sswang/NFT_search/NFT_Search_ETHBJ_2024/data/ETHBJ_top100_extraction_projects_index.csv\")\n",
    "# 使用pandas读取csv文件\n",
    "top100_index = pd.read_csv(top100_extraction_projects_index_path)\n",
    "\n",
    "candidate_NFT_list = [\n",
    "        \"BoredApeYachtClub\",\n",
    "        \"CRYPTOPUNKS\",\n",
    "        \"MutantApeYachtClub\",\n",
    "        \"Azuki\",\n",
    "        \"CloneX\",\n",
    "        \"Moonbirds\",\n",
    "        \"Doodles\",\n",
    "        \"BoredApeKennelClub\",\n",
    "        \"Cool Cats\",\n",
    "        \"Beanz\",\n",
    "        \"PudgyPenguins\",\n",
    "        \"Cryptoadz\",\n",
    "        \"World Of Women\",\n",
    "        \"CyberKongz\",\n",
    "        \"0N1 Force\",\n",
    "        \"MekaVerse\",\n",
    "        \"HAPE PRIME\",\n",
    "        \"mfers\",\n",
    "        \"projectPXN\",\n",
    "        \"Karafuru\",\n",
    "        \"Invisible Friends\",\n",
    "        \"FLUF\",\n",
    "        \"Milady\",\n",
    "        \"goblintown\",\n",
    "        \"Phanta Bear\",\n",
    "        \"CyberKongz VX\",\n",
    "        \"KaijuKingz\",\n",
    "        \"Prime Ape Planet\",\n",
    "        \"Lazy Lions\",\n",
    "        \"3Landers\",\n",
    "        \"The Doge Pound\",\n",
    "        \"DeadFellaz\",\n",
    "        \"World Of Women Galaxy\",\n",
    "        \"ALIENFRENS\",\n",
    "        \"VOX Series 1\",\n",
    "        \"Hashmasks\",\n",
    "        \"Psychedelics Anonymous Genesis\",\n",
    "        \"RENGA\",\n",
    "        \"CoolmansUniverse\",\n",
    "        \"Art Gobblers\",\n",
    "        \"SupDucks\",\n",
    "        \"Jungle Freaks\",\n",
    "        \"Sneaky Vampire Syndicate\",\n",
    "        \"SuperNormalbyZipcy\",\n",
    "        \"Nakamigos\",\n",
    "        \"Impostors Genesis\",\n",
    "        \"Potatoz\",\n",
    "        \"CryptoSkulls\",\n",
    "        \"Moonbirds Oddities\",\n",
    "        \"RumbleKongLeague\",\n",
    "        \"MURI\",\n",
    "        \"Galactic Apes\",\n",
    "        \"Lives of Asuna\",\n",
    "        \"My Pet Hooligan\",\n",
    "        \"Murakami.Flowers\",\n",
    "        \"Kiwami\",\n",
    "        \"SHIBOSHIS\",\n",
    "        \"Sappy Seals\",\n",
    "        \"DEGEN TOONZ\",\n",
    "        \"Killer GF\",\n",
    "        \"CryptoMories\",\n",
    "        \"Crypto Bull Society\",\n",
    "        \"CryptoBatz by Ozzy Osbourne\",\n",
    "        \"Quirkies\",\n",
    "        \"Robotos\",\n",
    "        \"Tubby Cats\",\n",
    "        \"Chain Runners\",\n",
    "        \"MutantCats\",\n",
    "        \"Boss Beauties\",\n",
    "        \"OnChainMonkey\",\n",
    "        \"Rektguy\",\n",
    "        \"Desperate ApeWives\",\n",
    "        \"DigiDaigaku\",\n",
    "        \"DeGods\",\n",
    "        \"apekidsclub\",\n",
    "        \"The Humanoids\",\n",
    "        \"Sevens Token\",\n",
    "        \"Akutars\",\n",
    "        \"HypeBears\",\n",
    "        \"KIA\",\n",
    "        \"inbetweeners\",\n",
    "        \"C-01 Official Collection\",\n",
    "        \"Imaginary Ones\",\n",
    "        \"ZombieClub Token\",\n",
    "        \"Groupies\",\n",
    "        \"Valhalla\",\n",
    "        \"MOAR by Joan Cornella\",\n",
    "        \"the littles NFT\",\n",
    "        \"The Heart Project\",\n",
    "        \"CryptoDads\",\n",
    "        \"Chimpers\",\n",
    "        \"Crypto Chicks\",\n",
    "        \"WonderPals\",\n",
    "        \"LilPudgys\",\n",
    "        \"a KID called BEAST\",\n",
    "        \"Akuma\",\n",
    "        \"Cyber Snails\",\n",
    "        \"Variant\",\n",
    "        \"OKOKU\",\n",
    "        \"Dodoor NFT\",\n",
    "        \"Weirdo Ghost Gang\"\n",
    "    ]\n",
    "\n",
    "for NFT_name in candidate_NFT_list:\n",
    "    print(\"processing: \", NFT_name)\n",
    "\n",
    "    # 按照NFT_name将原始数据分割，如果top100_index的NFT_name列的数据与NFT_name相等，则将该行数据保存到NFT_name_index.csv文件中\n",
    "    NFT_name_index = top100_index[top100_index['NFT_name'] == NFT_name]\n",
    "    # 给新表加上一样的列名\n",
    "    NFT_name_index.columns = top100_index.columns\n",
    "    # 保存到csv文件\n",
    "    csv_path = Path(\"/data/sswang/data/NFT1000_features_ETHBJ/\").joinpath(NFT_name, NFT_name + \"_index.csv\").as_posix()\n",
    "    NFT_name_index.to_csv(csv_path, index=False)\n",
    "    print(\"已完成：\", NFT_name)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NFT_Search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
